### SQL操作

2020年11月24日[Tue] / STAR Project

阿部一也

---

### アジェンダ

* 特別講演
* お知らせ
* SQL操作
* まとめ
* 連絡事項

---

### 特別講演（村井康介さん）

<img src="/slide08-base/images/izaki-san.jpg" height="480">

---

### お知らせ

* [VUCA Labo #7](https://peatix.com/event/1696240/view)
  * 11/26（木） 20:00〜21:30
    * 〜サスティナルブルな地域社会の創り方〜
* [みんなのPython勉強会#64](https://startpython.connpass.com/event/195410/)
  * 12/09（水） 19:00〜21:00
* [Fin-JAWS](https://fin-jaws.connpass.com/event/195041/)
  * 12/09（水） 19:00〜21:00
* [フィンテックトレンド 2021](https://fintech-engineer.connpass.com/event/193987/)
  * 12/11（金） 19:00〜21:30
    * 〜ニューノーマル時代に不可欠なコンパスを持ち歩く〜
* [X-Tech JAWS]
  * 12/21（月） 19:00〜21:00
* [Fin-JAWS]
  * 12/22（火） 19:00〜21:00

+++

### [11/26]VUCA Labo #7

https://peatix.com/event/1696240/view

<img src="/slide07-base/images/vucalabo07.png" height="480">

+++

### [12/11]フィンテックトレンド 2021

https://fintech-engineer.connpass.com/event/193987/

<img src="/slide07-base/images/finengine11.png" height="480">

---

### データベースに関するお薦め図書

<a href="https://www.shoeisha.co.jp/book/detail/9784798158341"><img src="/slide06-base/images/pandas8.jpg" height="150"></a>　
<a href="https://www.oreilly.co.jp/books/9784873118451/"><img src="/slide06-base/images/pandas4.jpg" height="150"></a>　
<a href="https://gihyo.jp/book/2020/978-4-297-11568-5"><img src="/slide06-base/images/pandas7.jpg" height="150"></a>　
<a href="https://www.shuwasystem.co.jp/book/9784798058757.html"><img src="/slide06-base/images/pandas2.jpg" height="150"></a><br>　

---

## データ処理

* Numpy
* pandas その1
* **pandas その2（今日の講義はこちら）**
 * データ読み込み
 * データのマージ
 * データの集計

+++

## Numpy

NumPyは科学技術計算に特化したサードパーティ製パッケージ

* 配列用の型であるndarray
* 行列用の型であるmatrix
* Numpyを利用する方法。

```python
>>> import numpy as np
```

+++

## pandas

pandasはPythonでのデータ分析のツールとして最も活用されており、データの入手や加工など多くのデータ処理に使われています。

* NumPyを基盤にシリーズ（Series）とデータフレーム（DataFrame）というデータ型を提供。
* pandasを利用する方法。

```python
>>> import pandas as pd
```

---

### pandasによるデータ読み込み

以下のファイル形式等を読み込むことができる。

```
CSVファイル,TSVファイル
jsonファイル
EXCELファイル
htmlファイル内のテーブル
その他（テーブル形式、HDF5ファイルなど）
```

+++

#### CSV,TSV

* CSVファイル（カンマ区切りのファイル）
* TSVファイル（タブ区切りのファイル）

+++

#### PandasによるCSV,TSVの読み込み

* read_csv()を利用する
* read_csv()の主なオプション

<img src="/slide07-base/images/pandas-read_csv.png" height="480">

+++

### 1.1.1 CSVファイル読み込み

* [CSVファイル](https://github.com/abenben/starproject-python/raw/master/sampledata/tutorial05/store.csv)はread_csvを利用する。

```python
[プログラム]
csv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.csv'
df = pd.read_csv(csv_file)
df
```

||店舗名|期首在庫数|売上数|仕入数|
|---|---|---|---|---|
|**0**|新宿店|100|50|100|
|**1**|池袋店|500|200|1000|
|**2**|銀座店|800|300|600|
|**3**|秋葉原店|300|100|500|
|**4**|大手町店|700|200|1000|

+++

#### 1.1.1(a) ヘッダー、カラムを指定

```python
[プログラム]
csv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.csv'
df = pd.read_csv(csv_file, index_col=0, header=0)
df
```

|**店舗名**|期首在庫数|売上数|仕入数|
|---|---|---|---|
|**新宿店**|100|50|100|
|**池袋店**|500|200|1000|
|**銀座店**|800|300|600|
|**秋葉原店**|300|100|500|
|**大手町店**|700|200|1000|

+++

#### 1.1.1(b) ヘッダー・カラムの指定無し

* Noneを指定する。

```python
[プログラム]
csv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.csv'
df = pd.read_csv(csv_file, index_col=None, header=None)
df
```

||0|1|2|3|
|---|---|---|---|---|
|**0**|店舗名|期首在庫数|売上数|仕入数|
|**1**|新宿店|100|50|100|
|**2**|池袋店|500|200|1000|
|**3**|銀座店|800|300|600|
|**4**|秋葉原店|300|100|500|
|**5**|大手町店|700|200|1000|


+++

#### 1.1.1(c) 任意のヘッダーを指定する

* namesを利用する。

```python
[プログラム]
csv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.csv'
df=pd.read_csv(csv_file, index_col=0, header=0,
               names=list(['店','在庫','売上','仕入']))
df
```

|**店**|在庫|売上|仕入|
|---|---|---|---|
|**新宿店**|100|50|100|
|**池袋店**|500|200|1000|
|**銀座店**|800|300|600|
|**秋葉原店**|300|100|500|
|**大手町店**|700|200|1000|

+++

#### 1.1.1(d) 列を絞って読み込む

```python
[プログラム]
csv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.csv'
df = pd.read_csv(csv_file, usecols=['店舗名','売上数'])
df
```

||店舗名|売上数|
|---|---|---|
|**0**|新宿店|50|
|**1**|池袋店|500|
|**2**|銀座店|300|
|**3**|秋葉原店|100|
|**4**|大手町店|200|

+++

#### 1.1.1(e) TSVファイル読み込み

* [TSVファイル](https://github.com/abenben/starproject-python/raw/master/sampledata/tutorial05/store.tsv)は、セパレータにタブ（\t）を指定する。

```python
[プログラム]
tsv_file = 'https://github.com/abenben/starproject-python/
            raw/master/sampledata/tutorial05/store.tsv'
df = pd.read_csv(tsv_file, index_col=0, sep='\t')
df
```

||店舗名|期首在庫数|売上数|仕入数|
|---|---|---|---|---|
|**0**|新宿店|100|50|100|
|**1**|池袋店|500|200|1000|
|**2**|銀座店|800|300|600|
|**3**|秋葉原店|300|100|500|
|**4**|大手町店|700|200|1000|

+++

### 1.1.2 EXCEL読み込み

* [EXCEL](https://github.com/abenben/starproject-python/raw/master/sampledata/tutorial05/store.xlsx)はread_excel()を利用する。

```python
[プログラム]
excel_file = 'https://github.com/abenben/starproject-python/
              raw/master/sampledata/tutorial05/store.xlsx'
df = pd.read_excel(excel_file)
df
```

||店舗名|期首在庫数|売上数|仕入数|
|---|---|---|---|---|
|**0**|新宿店|100|50|100|
|**1**|池袋店|500|200|1000|
|**2**|銀座店|800|300|600|
|**3**|秋葉原店|300|100|500|
|**4**|大手町店|700|200|1000|

+++

### 1.1.2 EXCEL読み込み（その２）

* read_excel()の中でxrldを利用するのでインストールが必要
* Google Colabでは事前にインストール済み

```shell
[コマンド]
pip install xrld
```

+++

### 1.1.3 jsonデータ読み込み

#### JSONとは

* JSONとはJavaScriptObjectNotationの略。
* データ定義文をベースとした軽量なデータ記述言語の1つ。
* JavaScript専用のデータ形式ではなう。
* 複数の言語間で円滑にデータの受け渡せるうように設計。
* JSONの詳しい扱い方は公式ドキュメントを参照ください。
* json.org URL : https://www.json.org/jsonja.html

+++

* [jsonファイル](https://github.com/abenben/starproject-python/raw/master/sampledata/tutorial05/store.json)はread_json()を利用する。

```python
json_file2 = 'https://github.com/abenben/starproject-python/
              raw/master/sampledata/tutorial05/store.json'
df = pd.read_json(json_file2)
df
```

||期首在庫数|売上数|仕入数|
|---|---|---|---|
|新宿店|100|50|100|
|池袋店|500|200|1000|
|銀座店|800|300|600|

+++

### 1.1.4 Webサイト上の表を読み込む

* io.html.read_html()を利用する。
* Webサイト上のテーブル(tableタグ)を読み込む
* 例：[Yahoo!株価情報（銘柄：日立）](https://stocks.finance.yahoo.co.jp/stocks/history/?code=6501.T)
* 複数まとめて読み込んでくれる（株価は２つ目のテーブル）

+++

```python
[プログラム]
from urllib.request import urlopen
url = 
 'https://stocks.finance.yahoo.co.jp/stocks/history/?code=6501.T'
f = urlopen(url)
html = f.read()
df = pd.io.html.read_html(html)
df[1]
```

||	日付|	始値|	高値|	安値|	終値|	出来高|	調整後終値*|
|--|--|--|--|--|--|--|--
|0	|2020年11月9日|	3548|	3606|	3548|	3591|	2175200|	3591|
|　：|：|：|：|：|：|：|：|


---

### pandasによるデータのマージ

複数のデータフレームに含まれる特定のカラムを基に1つにまとめることをマージという。

pandasのマージはmerge()を利用する。

+++

### 1.2.1 1対1のマージ（同じキー名） 

同じキー名でマージする場合は、mege関数のonオプションを利用する。

+++

元データ1（左側）

```python
[プログラム1]
leftdf = pd.DataFrame({
    '身長':[165,181,173],
    '体重':[56,68,73],
    '名前':['鈴木洋子','田中二郎','鈴木一郎'],
})
leftdf
```

||身長|体重|名前|
|-|-|-|-|
|0|165|56|鈴木洋子|
|1|181|68|田中二郎|
|2|173|73|鈴木一郎|

+++

元データ２（右側）

```python
[プログラム2]
rightdf = pd.DataFrame({
    '名前':['鈴木洋子','田中二郎','鈴木一郎'],
    '国語':[87,86,65],
    '数学':[83,90,74],
})
rightdf
```

||名前|国語|数学|
|-|-|-|-|
|0|鈴木洋子|87|83|
|1|田中二郎|86|90|
|2|鈴木一郎|65|74|

+++

データ1（右側）とデータ２（右側）をマージする

```python
[プログラム3]
pd.merge(leftdf, rightdf, on='名前')
```

|身長|体重|名前|国語|数学|
|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|
|1|181|68|田中二郎|86|90|
|2|173|73|鈴木一郎|65|74|


+++

### 1.2.2 1対1のマージ（キー名が異なる）

異なるキー名でマージする場合は、mege関数のleft_on,right_onオプションを利用する。

+++

元データ1（左側）

```python
[プログラム1]
leftdf = pd.DataFrame({
    '身長':[165,181,173],
    '体重':[56,68,73],
    '名前':['鈴木洋子','田中二郎','鈴木一郎'],
})
leftdf
```

||身長|体重|名前|
|-|-|-|-|
|0|165|56|鈴木洋子|
|1|181|68|田中二郎|
|2|173|73|鈴木一郎|

+++

元データ２（右側）

```python
[プログラム2]
rightdf = pd.DataFrame({
    '国語':[87,86,65],
    '数学':[83,90,74],
    '氏名':['鈴木洋子','田中二郎','鈴木一郎'],
})
rightdf
```

||国語|数学|氏名|
|-|-|-|-|
|0|87|83|鈴木洋子|
|1|86|90|田中二郎|
|2|65|74|鈴木一郎|

+++

キーの異なるデータ1（右側）とデータ２（右側）をマージする

```python
[プログラム3]
pd.merge(leftdf, rightdf, left_on='名前', right_on='氏名')
```

||身長|体重|名前|国語|数学|氏名|
|-|-|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|鈴木洋子|
|1|181|68|田中二郎|86|90|田中二郎|
|2|173|73|鈴木一郎|65|74|鈴木一郎|

+++

### 1.1.3 1対1のマージ（結合方法）

* 結合方法にはいくつかの種類がある。
* 結合方法(merge関数のhowオプション）

|howオプション|概要|
|-|-|
|inner|内部結合、両方のデータフレームの積集合|
|outer|外部結合、両方のデータフレームの和集合|
|left|１番目（左辺）のデータフレームのキーのみ使用|
|right|2番目（右辺）のデータフレームのキーのみ使用|

+++

元データ1（左辺）

```python
[プログラム1]
leftdf = pd.DataFrame({
    '身長':[165,181,173,160],
    '体重':[56,68,73,54],
    '名前':['鈴木洋子','田中二郎','鈴木一郎','斎藤美穂子'],
})
leftdf
```

||身長|体重|名前|
|-|-|-|-|
|0|165|56|鈴木洋子|
|1|181|68|田中二郎|
|2|173|73|鈴木一郎|
|3|160|54|斎藤美穂子|

+++

元データ２（右側）

```python
[プログラム2]
rightdf = pd.DataFrame({
    '名前':['鈴木洋子','田中二郎','鈴木一郎','佐藤利夫'],
    '国語':[87,86,65,50],
    '数学':[83,90,74,61],
})
rightdf
```

||名前|国語|数学|
|-|-|-|-|
|0|鈴木洋子|87|83|
|1|田中二郎|86|90|
|2|鈴木一郎|65|74|
|3|佐藤利夫|50|61|

+++

#### 内部結合

```python
[プログラム3]
pd.merge(leftdf, rightdf, on='名前', how='inner')
```

||身長|体重|名前|国語|数学|
|-|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|
|1|181|68|田中二郎|86|90|
|2|173|73|鈴木一郎|65|74|

+++

#### 外部結合

```python
[プログラム4]
pd.merge(leftdf, rightdf, on='名前', how='outner')
```

||身長|体重|名前|国語|数学|
|-|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|
|1|181|68|田中二郎|86|90|
|2|173|73|鈴木一郎|65|74|
|3|160|54|斎藤美穂子|NaN|NaN|
|4|NaN|NaN|佐藤利夫|50.0|61.0|

+++

#### 左辺結合

```python
[プログラム5]
pd.merge(leftdf, rightdf, on='名前', how='left')
```

||身長|体重|名前|国語|数学|
|-|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|
|1|181|68|田中二郎|86|90|
|2|173|73|鈴木一郎|65|74|
|3|160|54|斎藤美穂子|NaN|NaN|

+++

#### 右辺結合

```python
[プログラム6]
pd.merge(leftdf, rightdf, on='名前', how='right')
```

||身長|体重|名前|国語|数学|
|-|-|-|-|-|-|
|0|165|56|鈴木洋子|87|83|
|1|181|68|田中二郎|86|90|
|2|173|73|鈴木一郎|65|74|
|4|NaN|NaN|佐藤利夫|50.0|61.0|

---

### データの集計

- 複雑な集計をしたい場合、ピボットテーブルと、クロス集計の機能が揃っている。
- ピボットテーブルは、複数項目（男 or 女等）からなるデータ（性別）がある時に、異なる属性などに分類して、様々な計算で集計したもの
- クロス集計は、複数項目（男 or 女等）からなるデータ（性別）がある時に、異なる属性などに分類して、その頻度数を集計したもの。
- ピボットテーブルは、値別に集計方法が変えられる。

+++

データのピボット集計

* サンプルデータの準備

```python
[プログラム1]
np.random.seed(seed=1)
scores = np.random.randint(60, 100, size=50).reshape(10, 5)
subs = ['国語', '数学', '理科', '社会', '英語']
df = pd.DataFrame(scores, columns=subs)
df['部活'] = np.random.choice(['サッカー','野球','テニス'], size=10)
df['性別'] = np.random.choice(['男','女'], size=10)
df
```

+++

|   |国語|数学|理科|社会|英語|  部活  |性別|
|--:|---:|---:|---:|---:|---:|--------|----|
|  0|  97|  72|  68|  69|  71|野球    |男  |
|  1|  65|  75|  60|  76|  61|野球    |女  |
|  2|  72|  67|  66|  85|  80|テニス  |女  |
|  3|  97|  78|  80|  71|  88|サッカー|女  |
|  4|  89|  74|  64|  83|  83|サッカー|男  |
|  5|  90|  92|  82|  73|  69|野球    |女  |
|  6|  67|  82|  61|  60|  77|テニス  |女  |
|  7|  68|  84|  73|  68|  90|テニス  |男  |
|  8|  67|  63|  66|  81|  63|野球    |女  |
|  9|  64|  84|  72|  86|  76|サッカー|女  |

+++

* 行を「性別」の属性別に集計（平均を算出）=計算できる項目は全て行われる

```python
[プログラム2]
pd.pivot_table(df, index='性別', aggfunc=np.mean)
```

|   |国語 |数学 |理科 |社会 |英語 |
|---|----:|----:|----:|----:|----:|
|女 |74.57|77.29|69.57|76.00|73.43|
|男 |84.67|76.67|68.33|73.33|81.33|

+++

* 行を「性別」の属性別に、「数学」だけを集計（平均を算出）

```python
[プログラム3]
pd.pivot_table(df, index='性別', values='数学')
```

|   |数学 |
|---|----:|
|女 |77.29|
|男 |76.67|

+++

* 行を「性別」の属性別に、「数学」と「英語」を集計（平均を算出）

```python
[プログラム4]
pd.pivot_table(df, index='性別', values=['数学','英語'])
```

|   |数学 |英語 |
|---|----:|----:|
|女 |77.29|73.43|
|男 |76.67|81.33|

+++

* 行を「部活」の属性別に、行を「性別」の属性別で集計（平均を算出）

```python
[プログラム5]
pd.pivot_table(df, index='部活',
               columns='性別',aggfunc=np.mean)
```

+++

|        |('国語', '女')|('国語', '男')|('数学', '女')|('数学', '男')|('理科', '女')|('理科', '男')|('社会', '女')|('社会', '男')|('英語', '女')|('英語', '男')|
|--------|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|-------------:|
|サッカー|          80.5|            89|         81.00|            74|         76.00|            64|         78.50|            83|         82.00|            83|
|テニス  |          69.5|            68|         74.50|            84|         63.50|            73|         72.50|            68|         78.50|            90|
|野球    |          74.0|            97|         76.67|            72|         69.33|            68|         76.67|            69|         64.33|            71|

+++

* 行を「性別」と「部活」による階層の属性別で集計（平均を算出）

```python
[プログラム6]
pd.pivot_table(df, index=['性別','部活'],
               aggfunc=np.mean)
```

+++

|                  |国語|数学 |理科 |社会 |英語 |
|------------------|---:|----:|----:|----:|----:|
|('女', 'サッカー')|80.5|81.00|76.00|78.50|82.00|
|('女', 'テニス')  |69.5|74.50|63.50|72.50|78.50|
|('女', '野球')    |74.0|76.67|69.33|76.67|64.33|
|('男', 'サッカー')|89.0|74.00|64.00|83.00|83.00|
|('男', 'テニス')  |68.0|84.00|73.00|68.00|90.00|
|('男', '野球')    |97.0|72.00|68.00|69.00|71.00|

+++

* 行を「性別」と「部活」による階層の属性別にして、「英語」の合計、最大、最低を算出

```python
[プログラム7]
pd.pivot_table(df, index=['性別','部活'],
               values='英語',
               aggfunc=[np.sum, np.max, np.min])
```

+++

|                  |('sum', '英語')|('amax', '英語')|('amin', '英語')|
|------------------|--------------:|---------------:|---------------:|
|('女', 'サッカー')|            164|              88|              76|
|('女', 'テニス')  |            157|              80|              77|
|('女', '野球')    |            193|              69|              61|
|('男', 'サッカー')|             83|              83|              83|
|('男', 'テニス')  |             90|              90|              90|
|('男', '野球')    |             71|              71|              71|

+++

* 行を「性別」と「部活」による階層の属性別にして、「英語」の最大と、「数学」の平均を算出

```python
[プログラム8]
pd.pivot_table(df, index=['性別','部活'],
               aggfunc={'英語':np.max, '数学':np.mean})
```

+++

|                  |('sum', '英語')|('amax', '英語')|('amin', '英語')|
|------------------|--------------:|---------------:|---------------:|
|('女', 'サッカー')|            164|              88|              76|
|('女', 'テニス')  |            157|              80|              77|
|('女', '野球')    |            193|              69|              61|
|('男', 'サッカー')|             83|              83|              83|
|('男', 'テニス')  |             90|              90|              90|
|('男', '野球')    |             71|              71|              71|

+++

* 行を「部活」の属性別に、「数学」を集計（平均を算出）、集計値の集計（平均）も指定

```python
[プログラム9]
pd.pivot_table(df, index='部活', values='数学',
               aggfunc=np.mean, margins=True)
```

|        |数学 |
|--------|----:|
|サッカー|78.67|
|テニス  |77.67|
|野球    |75.50|
|All     |77.10|

+++

* 行を「部活」の属性別に、列を「性別」の属性別に、「数学」を集計（平均を算出）、集計値の集計（平均）も指定

```python
[プログラム10]
pd.pivot_table(df, index='部活', columns='性別',
               values='数学',
               aggfunc=np.mean, margins=True)
```

|        | 女  | 男  | All |
|--------|----:|----:|----:|
|サッカー|81.00|74.00|78.67|
|テニス  |74.50|84.00|77.67|
|野球    |76.67|72.00|75.50|
|All     |77.29|76.67|77.10|

+++

### 1.3.2 データのクロス集計

* サンプルデータの準備

```python
[プログラム1]
import numpy as np
np.random.seed(seed = 1)
sex = np.random.choice(['男','女'], size=10)
eva = np.random.randint(70,100, size=10)
city = np.random.choice(['東京','大阪','名古屋'], size=10)
div = np.random.choice(['開発','営業','人事','販促'], size=10)
dic = {'営業所':city, '部門':div,'性別':sex, '評価':eva}
df = pd.DataFrame(dic)
df
```

+++

|   |営業所|部門|性別|評価|
|--:|------|----|----|---:|
|  0|名古屋|開発|女  |  86|
|  1|大阪  |販促|女  |  71|
|  2|名古屋|販促|男  |  82|
|  3|東京  |営業|男  |  77|
|  4|東京  |営業|女  |  83|
|  5|名古屋|販促|女  |  98|
|  6|東京  |人事|女  |  76|
|  7|大阪  |開発|女  |  95|
|  8|名古屋|人事|女  |  88|
|  9|名古屋|営業|男  |  90|

+++

* 行を「性別」の属性別、列を「営業所」の属性別に集計（頻度算出）

```python
[プログラム2]
pd.crosstab(index=df['性別'], columns=df['営業所'])
```

|   |名古屋|大阪|東京|
|---|-----:|---:|---:|
|女 |     3|   2|   2|
|男 |     2|   0|   1|

+++

* 行を「性別,営業所」の属性別、列を「部門」の属性別に集計（頻度算出）

```python
[プログラム3]
pd.crosstab(index=[df['性別'], df['営業所']],
            columns=df['部門'])
```

|                |人事|営業|販促|開発|
|----------------|---:|---:|---:|---:|
|('女', '名古屋')|   1|   0|   1|   1|
|('女', '大阪')  |   0|   0|   1|   1|
|('女', '東京')  |   1|   1|   0|   0|
|('男', '名古屋')|   0|   1|   1|   0|
|('男', '東京')  |   0|   1|   0|   0|

+++

* 行を「性別,営業所」の属性別、列を「部門」の属性別に集計（頻度算出）
* 属性別の集計も算出

```python
[プログラム4]
pd.crosstab(index=[df['性別'], df['営業所']],
            columns=df['部門'], margins=True)
```

|                |人事|営業|販促|開発|All|
|----------------|---:|---:|---:|---:|--:|
|('女', '名古屋')|   1|   0|   1|   1|  3|
|('女', '大阪')  |   0|   0|   1|   1|  2|
|('女', '東京')  |   1|   1|   0|   0|  2|
|('男', '名古屋')|   0|   1|   1|   0|  2|
|('男', '東京')  |   0|   1|   0|   0|  1|
|('All', '')     |   2|   3|   3|   2| 10|

+++

* 行を「性別」の属性別、列を「営業所」の属性別に集計（平均を算出）

```python
[プログラム5]
pd.crosstab(index=df['性別'], columns=df['営業所'],
            values=df['評価'], aggfunc=np.mean)
```

|   |名古屋|大阪|東京|
|---|-----:|---:|---:|
|女 | 90.67|  83|79.5|
|男 | 86.00| NaN|77.0|

---

### まとめ（pandasのデータ処理）

* 様々な形式のデータを直接取り込める
* 複数のデータフレームを自由に結合できる
* 複雑な集計が行える

---

### (参考)Pythonドキュメント

* [Pythonメインサイト日本語版](https://www.python.jp/)
* [Python言語リファレンス](https://docs.python.org/ja/3/reference/index.html)
* [Python標準リファレンス](https://docs.python.org/ja/3/library/)
* [numpyリファレンス](https://numpy.org/doc/stable/reference/)
* [pandasリファレンス](https://pandas.pydata.org/docs/reference/index.html)

---

### 次回のブロックチェーン講義

* 『これからのデータ社会で活躍するために身につけるべきプライバシースキル』
* 2020/12/15(火) 19:00〜

```
①プライバシーがなぜ重要なのか？（20分） 栗原 宏平さん
②ワークショップ：プライバシーを理解するワークショップ（40分） 
```
 
+++

### ゲスト 栗原 宏平さん

Privacy by Design Lab 代表理事

大学時代にマーケティングを専攻し、議員秘書やNPOでのイベント運営に携わる。CollaboGate JapanではCMOとして大企業向けのブロックチェーンIDのデータ認証基盤開発を行う。ビジネス、政府領域のブロックチェーン及びビジネス領域でのデータプライバシー専門家として、ユネスコを始め国際学会などで積極的に情報発信を行う。アメリカのワシントンDCを拠点に全世界に展開するNPO法人Government Blockchain Associationの日本代表を兼務。

---

### 次回のPython講義

2020/12/01(火) 19:00〜

* チュートリアル
 * 『データベース操作』

---

### コアメンバーからのお知らせ
